version: '3.8'

# Prototype: Open WebUI + Keycloak for testing __user__ context injection
# Task: pfn_mcp-6ar - Verify __user__ context in Open WebUI Python tools
# VPS: 88.222.213.96

services:
  postgres-keycloak:
    image: postgres:16-alpine
    container_name: proto-postgres-keycloak
    environment:
      - POSTGRES_DB=keycloak
      - POSTGRES_USER=keycloak
      - POSTGRES_PASSWORD=${KC_DB_PASSWORD:-keycloak}
    volumes:
      - keycloak-db-data:/var/lib/postgresql/data
    networks:
      - proto-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U keycloak"]
      interval: 5s
      timeout: 5s
      retries: 5

  keycloak:
    image: quay.io/keycloak/keycloak:26.0
    container_name: proto-keycloak
    environment:
      - KC_BOOTSTRAP_ADMIN_USERNAME=admin
      - KC_BOOTSTRAP_ADMIN_PASSWORD=${KC_ADMIN_PASSWORD:-admin}
      - KC_HTTP_ENABLED=true
      - KC_HOSTNAME_URL=https://auth.forsanusa.id
      - KC_HOSTNAME_STRICT=false
      - KC_HOSTNAME_STRICT_HTTPS=false
      - KC_PROXY_HEADERS=xforwarded
      # Database
      - KC_DB=postgres
      - KC_DB_URL=jdbc:postgresql://postgres-keycloak:5432/keycloak
      - KC_DB_USERNAME=keycloak
      - KC_DB_PASSWORD=${KC_DB_PASSWORD:-keycloak}
    ports:
      - "127.0.0.1:8080:8080"
    command: start-dev
    depends_on:
      postgres-keycloak:
        condition: service_healthy
    networks:
      - proto-net
    healthcheck:
      test: ["CMD-SHELL", "exec 3<>/dev/tcp/localhost/8080"]
      interval: 10s
      timeout: 5s
      retries: 10

  # PostgreSQL for LiteLLM budget/spend tracking
  litellm-db:
    image: postgres:16-alpine
    container_name: proto-litellm-db
    environment:
      - POSTGRES_DB=litellm
      - POSTGRES_USER=litellm
      - POSTGRES_PASSWORD=${LITELLM_DB_PASSWORD:-litellm}
    volumes:
      - litellm-db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U litellm"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - proto-net

  # LiteLLM Proxy with budget enforcement
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: proto-litellm
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - MINIMAX_API_KEY=${MINIMAX_API_KEY}
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY}
      - LITELLM_DATABASE_URL=postgresql://litellm:${LITELLM_DB_PASSWORD:-litellm}@litellm-db:5432/litellm
    volumes:
      - ./litellm-config.yaml:/app/config.yaml
    ports:
      - "127.0.0.1:4001:4000"
    command: ["--config", "/app/config.yaml"]
    depends_on:
      litellm-db:
        condition: service_healthy
    networks:
      - proto-net
    healthcheck:
      test: ["CMD-SHELL", "python3 -c \"import urllib.request; urllib.request.urlopen('http://localhost:4000/health/liveliness')\" || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

  # PFN MCP Server - SSE transport
  # Energy monitoring tools for Open WebUI
  pfn-mcp:
    build:
      context: ..
      dockerfile: Dockerfile
    container_name: proto-pfn-mcp
    environment:
      - DATABASE_URL=${PFN_DATABASE_URL}
    networks:
      - proto-net
    healthcheck:
      test: ["CMD-SHELL", "python3 -c \"import urllib.request; urllib.request.urlopen('http://localhost:8000/health')\" || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

  # MCPO - MCP to OpenAPI proxy
  # Bridges SSE MCP server to OpenAPI for Open WebUI
  mcpo:
    image: ghcr.io/open-webui/mcpo:main
    container_name: proto-mcpo
    command: ["--port", "8000", "--server-type", "sse", "--", "http://pfn-mcp:8000/sse"]
    ports:
      - "127.0.0.1:8001:8000"
    depends_on:
      pfn-mcp:
        condition: service_healthy
    networks:
      - proto-net
    healthcheck:
      test: ["CMD-SHELL", "python3 -c \"import urllib.request; urllib.request.urlopen('http://localhost:8000/')\" || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: proto-openwebui
    environment:
      # LiteLLM connection
      - OPENAI_API_BASE_URL=http://litellm:4000/v1
      - OPENAI_API_KEY=${LITELLM_MASTER_KEY}
      # Forward user info to LiteLLM for budget tracking
      - ENABLE_FORWARD_USER_INFO_HEADERS=true
      # OAuth Configuration
      - ENABLE_OAUTH_SIGNUP=true
      - OAUTH_PROVIDER_NAME=Keycloak
      - OPENID_PROVIDER_URL=https://auth.forsanusa.id/realms/pfn/.well-known/openid-configuration
      - OAUTH_CLIENT_ID=openwebui
      - OAUTH_CLIENT_SECRET=${OAUTH_CLIENT_SECRET}
      - OAUTH_SCOPES=openid email profile groups
      # Group sync from OAuth
      - ENABLE_OAUTH_GROUP_MANAGEMENT=true
      - OAUTH_GROUP_CLAIM=groups
      - ENABLE_OAUTH_GROUP_CREATION=true
      # WebUI settings
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}
      - WEBUI_URL=https://chat.forsanusa.id
      - WEBUI_AUTH_SIGNOUT_REDIRECT_URL=https://chat.forsanusa.id/
      # Disable default login form for OAuth-only
      - ENABLE_LOGIN_FORM=false
      # Disable Ollama (using LiteLLM)
      - OLLAMA_BASE_URL=
    ports:
      - "127.0.0.1:3000:8080"
    volumes:
      - open-webui-data:/app/backend/data
    depends_on:
      keycloak:
        condition: service_healthy
      litellm:
        condition: service_healthy
      mcpo:
        condition: service_healthy
    networks:
      - proto-net

volumes:
  keycloak-db-data:
  litellm-db-data:
  open-webui-data:

networks:
  proto-net:
    driver: bridge
